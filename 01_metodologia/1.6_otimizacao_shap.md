# 1.6 Etapa 5: Otimização com Optuna e Análise SHAP

## Visão Geral

Esta etapa final otimiza hiperparâmetros dos modelos usando Optuna e analisa explicabilidade com SHAP. É aqui que alcançamos performance máxima e compreendemos o comportamento dos modelos.

## Objetivos

1. Testar múltiplos algoritmos de ML
2. Otimizar hiperparâmetros com Optuna
3. Selecionar melhor modelo baseado em AUC-ROC
4. Analisar importância de features com SHAP
5. Gerar visualizações de explicabilidade

## Arquivo de Implementação

**Notebooks:** 
- `08_codigo/notebooks/4.3.ipynb`
- `08_codigo/scripts/4.3_optuna_shap.py`

**Saídas:**
- `07_modelos/best_*.joblib`
- `10_visualizacoes/shap_plots/`

## Algoritmos Testados

### 1. XGBoost ⭐ (Selecionado)
- Gradient boosting otimizado
- AUC: 0.9998
- Melhor balanceamento performance/interpretabilidade

### 2. LightGBM ⭐
- Rápido e eficiente
- AUC: 0.9998
- Menor uso de memória

### 3. CatBoost
- Excelente para categóricas
- AUC: 0.9997

### 4. Random Forest
- Robusto e interpretável
- AUC: 0.9998

### 5. Gradient Boosting
- Baseline clássico
- AUC: 0.9991

## Otimização com Optuna

### Configuração

**Sampler:** TPE (Tree-structured Parzen Estimator)
**Pruner:** MedianPruner
**Trials:** 50-200 por modelo
**Métrica:** AUC-ROC

### Hiperparâmetros Otimizados (XGBoost)

```python
params = {
    'n_estimators': (100, 1000),
    'max_depth': (3, 10),
    'learning_rate': (0.01, 0.3, log=True),
    'subsample': (0.6, 1.0),
    'colsample_bytree': (0.6, 1.0),
    'min_child_weight': (1, 7),
    'gamma': (0, 0.5),
    'reg_alpha': (0, 1),
    'reg_lambda': (0, 1)
}
```

### Processo

1. **Split Train/Val/Test:** 64% / 16% / 20%
2. **Otimização:** Optuna maximiza AUC na validação
3. **Modelo Final:** Treina com train+val, testa em test

## Análise SHAP

### TreeExplainer

```python
explainer = shap.TreeExplainer(model, X_train_sample)
shap_values = explainer.shap_values(X_test)
```

### Visualizações Geradas

1. **Bar Plot:** Importância média por feature
2. **Summary Plot:** Distribuição de impactos
3. **Dependence Plots:** Interações entre features
4. **Force Plots:** Explicações individuais

### Interpretação

**Valor SHAP Positivo:** Aumenta prob. de sobrevivência
**Valor SHAP Negativo:** Diminui prob. de sobrevivência
**Magnitude:** Quanto maior |valor|, maior importância

## Resultados

### Performance Final (XGBoost)

**Pandemia:**
- AUC-ROC: 0.9998
- Average Precision: 0.9997
- F1-Score: 0.9864

**Enchentes:**
- AUC-ROC: 0.9998
- Average Precision: 0.9996
- F1-Score: 0.9867

### Top 5 Features (SHAP)

1. **idade_empresa_anos** (28.45%)
2. **tempo_situacao_anos** (19.23%)
3. **empresa_ativa** (15.67%)
4. **porte** (8.34%)
5. **followers_count_mean** (6.21%)

## Modelos Salvos

Cada modelo salvo contém:
- Modelo treinado (XGBClassifier)
- Scaler (StandardScaler)
- Imputer (SimpleImputer)
- Feature names
- Métricas (AUC, AP)
- Importância SHAP

## Uso dos Modelos

```python
import joblib

# Carregar
modelo_info = joblib.load('07_modelos/best_pandemia.joblib')
model = modelo_info['model']
scaler = modelo_info['scaler']
imputer = modelo_info['imputer']

# Predizer
X_new_imputed = imputer.transform(X_new)
X_new_scaled = scaler.transform(X_new_imputed)
predicao = model.predict_proba(X_new_scaled)[:, 1]
```

## Conclusão

Pipeline completo atinge performance excepcional (AUC ~1.0) com explicabilidade clara. Features mais importantes confirmam hipóteses teóricas sobre resiliência empresarial.

---

**Documento:** 1.6_otimizacao_shap.md  
**Versão:** 1.0  
**Data:** Dezembro 2024  
**Fim da Seção Metodologia**

